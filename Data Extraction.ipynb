{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import glob\n",
    "import nltk\n",
    "import glob\n",
    "import cv2\n",
    "import spacy\n",
    "import spacy.cli\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import textseg as ts\n",
    "from spacy import displacy\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' #tesseract.exe location in your computer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# SKILLS EXTRACTION\n",
    "# Add skills database from a file\n",
    "def add_skills_data(filePath):\n",
    "    skills = []\n",
    "\n",
    "    for data in open(filePath, 'r', encoding='UTF-8'):\n",
    "        skills.append(data.strip())\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Get the text from a file\n",
    "def extract_text(filePath, remove_line=False):\n",
    "    with fitz.open(filePath) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        if remove_line:\n",
    "            text = text = re.sub('\\s', \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Extract the skills based on the skill database\n",
    "def extract_skills(input_text, skills_data):\n",
    "    stop_word = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    "\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_word]\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    "\n",
    "    skills = set() #penampung skill\n",
    "\n",
    "    for token in filtered_tokens:\n",
    "        if token in skills_data:\n",
    "            skills.add(token)\n",
    "\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram in skills_data:\n",
    "            skills.add(ngram)\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Extract skills from a single file\n",
    "def extract_single_skills(filePath, skills):\n",
    "    text = extract_text(filePath)\n",
    "\n",
    "    return  extract_skills(text, skills)\n",
    "\n",
    "# Extract skills from a folder full of pdf\n",
    "def extract_batch_skill(filePath, skills):\n",
    "    data = {\"File\": [], 'Skill': []}\n",
    "\n",
    "    for file in glob.glob('{}*.pdf'.format(filePath)):\n",
    "        text = extract_text(file, True)\n",
    "        data['File'].append(file)\n",
    "        data['Skill'].append(extract_skills(text, skills))\n",
    "\n",
    "    return data\n",
    "\n",
    "# DOCUMENT SEGMENTATION\n",
    "# Converting from pdf to image for segmentation\n",
    "def convert_pdf_to_image(filepath,img_path_to_save):\n",
    "    try:\n",
    "        fileName = filepath.split(\"/\")[-1].replace(\".pdf\",\"\")\n",
    "        pages = convert_from_path(filepath, 350)\n",
    "        i = 1\n",
    "        for page in pages:\n",
    "            image_name = img_path_to_save+fileName+\"Page_\" + str(i) + \".png\"\n",
    "            page.save(image_name, \"JPEG\")\n",
    "            i = i+1\n",
    "        return {\"status\":200,\"response\":\"PDF Converted to image sucessfully\",\"fileName\":fileName}\n",
    "    except Exception as e:\n",
    "        return {\"status\":400,\"response\":str(e)}\n",
    "\n",
    "# Extract text from a png\n",
    "def text_from_tesseract(output_img):\n",
    "    text = str(((pytesseract.image_to_string(output_img))))\n",
    "    return text\n",
    "\n",
    "def text_from_easyocr(img, reader):\n",
    "    all_text = \"\"\n",
    "    result = reader.readtext(img)\n",
    "\n",
    "    for (bbox, text, prob) in result:\n",
    "        all_text += text + \" \"\n",
    "\n",
    "    return all_text\n",
    "\n",
    "\n",
    "# Segment and then extract the data from a resume\n",
    "def segment_extract_data(data,  path_to_write, reader, singleFile=True):\n",
    "    documents = [] # file path nya untuk pdf\n",
    "\n",
    "    if singleFile:\n",
    "        documents.append(data)\n",
    "    else:\n",
    "        documents = data\n",
    "\n",
    "    final_name_list=[] # nama file\n",
    "    final_text_opencv=[] # text dengan segmen\n",
    "    # final_text_tessaract=[]\n",
    "    final_text_easyocr=[] # semua text tanpa segmen\n",
    "    for i in documents:\n",
    "        pdf = PdfFileReader(open(i,'rb'))\n",
    "        fname = i.split('/')[-1]\n",
    "\n",
    "        # if pdf.getNumPages() > 3:\n",
    "        #     print('Pages to many : {}!, Skipping...'.format(pdf.getNumPages()))\n",
    "        #     continue\n",
    "\n",
    "        images = convert_from_path(i)\n",
    "        resumes_img=[]\n",
    "        for j in range(len(images)):\n",
    "            # Save pages as images in the pdf\n",
    "            images[j].save(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg', 'JPEG')\n",
    "            resumes_img.append(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg')\n",
    "        name_list = fname.split('.')[0]+'_' +'.jpg'\n",
    "        text_opencv=[]\n",
    "        # text_tessaract=[]\n",
    "        text_easyocr=[]\n",
    "        for i in resumes_img:\n",
    "            frame=cv2.imread(i)\n",
    "            os.remove(i)\n",
    "            img = i.split(\"/\")[2]\n",
    "\n",
    "            output_img,label,dilate, c_dict,df1, split_img=ts.get_text_seg(frame, img)\n",
    "            cv2.imwrite(path_to_write+img.split('.')[0]+\".png\",output_img)\n",
    "            for i in range(len(split_img)):\n",
    "                cv2.imwrite(path_to_write+img.split('.')[0]+str(i)+\".png\", split_img[i])\n",
    "\n",
    "            text_opencv.append(c_dict)\n",
    "            # text_tessaract+=text_from_tesseract(output_img)\n",
    "            # tesseract_str = ''.join(text_tessaract)\n",
    "            text_easyocr+=text_from_easyocr(output_img, reader)\n",
    "            easyocr_str = ''.join(text_easyocr)\n",
    "\n",
    "        final_name_list.append(name_list)\n",
    "        final_text_opencv.append(text_opencv)\n",
    "        # final_text_tessaract.append(tesseract_str)\n",
    "        final_text_easyocr.append(easyocr_str)\n",
    "\n",
    "    return final_text_opencv, final_name_list, final_text_easyocr\n",
    "\n",
    "# EXPERIENCE EXTRACTION\n",
    "# Extract exp from a text\n",
    "def extract_exp(textList, nlp):\n",
    "    exp = []\n",
    "\n",
    "    for i in range(len(textList)):\n",
    "        for j in range(len(textList[i])):\n",
    "            for _, text in textList[i][j].items():\n",
    "                text = re.sub(r'[^\\w\\s]+', \"\", text)\n",
    "                text = re.sub(r'[\\s]{2,}', \" \", text)\n",
    "                text = re.sub(r'https\\w+', \"\", text)\n",
    "                doc = nlp(text)\n",
    "                if doc.cats['experience'] > 0.70:\n",
    "                    exp.append(text)\n",
    "\n",
    "    return exp\n",
    "\n",
    "# Do all the above with just 1 function\n",
    "def extract_data(filePath, skills, nlp, temp_path, reader):\n",
    "    file_data = {'File': \"\", 'Skills':\"\", \"Exp\":\"\"}\n",
    "\n",
    "    textList, fileName, fullText = segment_extract_data(filePath, temp_path, reader)\n",
    "    file_data['File'] = fileName[0]\n",
    "    file_data['Skills'] = extract_skills((fullText[0]), skills_data=skills)\n",
    "    file_data['Exp'] = extract_exp(textList, nlp)\n",
    "\n",
    "    return file_data\n",
    "\n",
    "def batch_extract_data(filePath, skills, nlp, temp_path):\n",
    "    file_data = {'File': [], 'Skills': [], \"Exp\": []}\n",
    "\n",
    "    for file in os.listdir(filePath):\n",
    "        data = extract_data('{}/{}'.format(filePath, file), skills, nlp, temp_path)\n",
    "        file_data['File'].append(data['File'])\n",
    "        file_data['Skills'].append(data['Skills'])\n",
    "        file_data['Exp'].append(data['Exp'])\n",
    "\n",
    "    return file_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU device\n",
      "[[{0: 'ALYA ATAYA\\n\\n6282376745433 | alyatayaa@gmail.com | https://www.linkedin.com/in/alya-ataya-30884411b\\n7, Anggrek 15B. Karet, Setiabudi.\\n\\n| am a Manager of Customer Service in Cariilmu with a problem-solving mindset, reconciliation, and collaborative experience.\\nvalue add and expand my horizons.\\n\\n', 1: '| hope to\\n\\n', 2: 'Work Experiences\\n\\n', 3: \"Cariilmu - Jakarta\\nManager of Customer Service\\n\\n¢ Set the customer service staff schedule (Host, Admin, Qontak Agent)\\n\\ne Report Qontak\\n\\n¢ Assist or replace the role of Customer Service Staff when needed (including replying to Qontak)\\n¢ Scheduling (Includes create zoom links & telegram groups)\\n\\n¢ Follow Up participants who haven't passed the quiz and haven't done the quiz\\n\\n¢ Send the data of participants who passed the quiz to the platform (Maubelajarapa)\\nCariilmu - Jakarta\\n\\nOperation & Product Development Intern\\n\\n¢ Host and admin pre-work webinars\\n\\n« Update webinar participants through google spreadsheets\\n\\n¢ Making module and conduct research related to competitors\\n\\nPunya Karya - Jakarta\\n\\nBusiness Development intern\\n\\n¢ Group listing for Micro Small and Medium Enterprises\\n\\n¢ Create customer communication framework.\\n\\n¢ Acquisition, training and evaluation as well as conducting research and developing results\\nThe Shonet - Jakarta\\n\\nCreative Intern\\n\\n¢ Assistant stylist in fashion and products in the photoshoot.\\n\\n¢ Check in, check out the product's brand.\\n\\n¢ Conducting brand that will take a photoshoot and Become a PIC for the brand in the studio.\\n¢ Helped the Merchant Team to bulk and rename photos and quality control.\\n\\n\", 4: 'Present\\n\\n', 5: 'Apr 2021\\n\\n', 6: 'Apr 2021\\n\\n', 7: 'Sep 2020\\n\\n', 8: 'Jun 2020 - Aug 2020\\n\\n', 9: 'Feb 2020 - Apr 2020\\n\\n', 10: 'Education Level\\n', 11: 'Jun 2018\\n\\n', 12: \"Sebelas Maret University - Surakarta\\nDiploma in Agribusiness, 3.60/4.00\\n\\nMercu Buana University - Jakarta\\nBachelor Degree in Management, 3.63/4.00\\n\\n¢ I'ma student here right now.\\n\\n\", 13: 'Sep 2015\\n\\n', 14: 'Mar 2020\\n\\n', 15: 'Organisational Experience\\n\\n', 16: 'Press Institute - Surakarta\\nStaff of Member Organization Development\\n\\n¢ Implementing the project provided such as upgrading new members and looking for journalism news.\\nStaff of Member Organization Development - Surakarta\\n\\nStudent Executive Board\\n\\n¢ Conducting activities such as training of internal members, training of new students and study orientation\\nHead of Member Development - Surakarta\\n\\nPress Institute, Sebelas Maret University\\n\\n¢ Leading 6 members and conduct training for internal members.\\n\\n', 17: 'Jan 2016\\n\\n', 18: 'Jan 2017\\n\\n', 19: 'Jan 2016\\n\\n', 20: 'Jan 2017\\n\\n', 21: 'Jan 2017 - Jan 2018\\n\\n', 22: 'Skills & Other Experience\\n', 23: 'Interest: Customer Service, Operations & Creative Fashion\\n\\nSoft Skills: Spreadsheet, Google Form, Microsoft Excel, Word & Power Point\\n\\n'}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'File': 'Alya Ataya_CV - Alya Ataya_.jpg',\n 'Skills': {'Agribusiness',\n  'Conducting',\n  'Customer Service',\n  'Excel',\n  'Member Development',\n  'Microsoft Excel',\n  'Operations',\n  'Organization',\n  'PIC',\n  'Power Point',\n  'Scheduling',\n  'Service Operations',\n  'Soft Skills',\n  'Word'},\n 'Exp': ['Cariilmu Jakarta\\nManager of Customer Service Set the customer service staff schedule Host Admin Qontak Agent e Report Qontak Assist or replace the role of Customer Service Staff when needed including replying to Qontak Scheduling Includes create zoom links telegram groups Follow Up participants who havent passed the quiz and havent done the quiz Send the data of participants who passed the quiz to the platform Maubelajarapa\\nCariilmu Jakarta Operation Product Development Intern Host and admin prework webinars Update webinar participants through google spreadsheets Making module and conduct research related to competitors Punya Karya Jakarta Business Development intern Group listing for Micro Small and Medium Enterprises Create customer communication framework Acquisition training and evaluation as well as conducting research and developing results\\nThe Shonet Jakarta Creative Intern Assistant stylist in fashion and products in the photoshoot Check in check out the products brand Conducting brand that will take a photoshoot and Become a PIC for the brand in the studio Helped the Merchant Team to bulk and rename photos and quality control ',\n  'Press Institute Surakarta\\nStaff of Member Organization Development Implementing the project provided such as upgrading new members and looking for journalism news\\nStaff of Member Organization Development Surakarta Student Executive Board Conducting activities such as training of internal members training of new students and study orientation\\nHead of Member Development Surakarta Press Institute Sebelas Maret University Leading 6 members and conduct training for internal members ']}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding skills database\n",
    "skills = add_skills_data('list_of_skills.txt')\n",
    "skills[0] = '.NET' # First skills is not UTF-8 so we need to replace it\n",
    "\n",
    "# Segmentation need a temp folder for storing image that will be scanned for extraction the text\n",
    "temp_path = ('./segmentation/')\n",
    "\n",
    "# Load the machine learning model for exp classification\n",
    "nlp = spacy.load('model/model_exp')\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Get the filename, skills, exp\n",
    "data = extract_data('./sample/cv/Alya Ataya_CV - Alya Ataya.pdf', skills, nlp, temp_path, reader)\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling [autocast_mode.py:162]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Summary \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Senior HC Staff\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n with Certified \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Human Capital Staff\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n specializing in databasing and analytics almost 19 000 employees Experienced with all stages of recruitment process and psychological test administration Basic skill in one of the programming language PHP Strong background in maintaining \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Human Capital Information System\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n HCIS Personal Info POB DOB Padang 22 January 1993 Status Married Skill Highlights \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    HC Specialist\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Database Administration\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n Data Analytic Web Programming PHP Graphics Design Adobe Photoshop Adobe Illustrator Adobe Premier Work Experience 6 years of total experience \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Talent Monitoring\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n Support Staff Feb 2021 Present Less than 1 year PT Bank Syariah Indonesia Tbk Jakarta Create and maintain talent pool information system dashboard using Google Data Studio and PowerBI Research analyze and present data to all leader such as Talent Summary Profile Learning and Development Performance Management and Succession Planning \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    People Development\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n Staff Jul 2020 Jan 2021 6 months PT Bank BNI Syariah Jakarta Collect data employee and identify candidates for the talent pool Develop training and development programs Develop and monitor Talent Development Succession Planning Maintain the talent pool career path AHMAD ZAKY NABHAN 62 813 1055 5622 zaky recruitment gmail com Depok West Java Indonesia  \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Recruitment Assessment Staff\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n Mar 2015 Jul 2020 5 years 4 months PT Bank BNI Syariah Jakarta Attend job fairs and recruitment events to build a strong candidate pipeline and source applicants through online channels Responsible for end to end recruitment and psychological test process from sourcing until onboarding Connect with the hiring manager for better understanding the hiring objectives and develop recruiting strategies to hit headcount goals Maintain relationship with candidates Control HC Administration Policies and Procedures Maintain \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Human Capital Information System\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n HCIS for almost 5 000 employees Employee Performance Rating PT Bank BNI Syariah 2020 2019 2018 based on the company s internal regulations Education Bachelor Informatics Engineering 2020 GPA 3 49 4 00 Mercu Buana University West Jakarta DKI Jakarta Diploma Computer Engineering 2014 GPA 3 08 4 00 Padang State Polytechnic Padang West Sumatera Certifications 2021 Certified \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Human Capital Staff\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n BNSP RI 2020 CCC Big Data Foundation 2018 Certified Secure Computer User CSCU Social Media LinkedIn www linkedin com in ahmad zaky nabhan Instagram zaky ahmad  Additional Info Preferred Work Location Banten DKI Jakarta West Java Jabodetabek West Sumatera </div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fitz\n",
    "import spacy\n",
    "import spacy.displacy\n",
    "\n",
    "nlp = spacy.load('model/model_job')\n",
    "\n",
    "def extract_text(filePath, remove_line=False):\n",
    "    with fitz.open(filePath) as doc:\n",
    "        finaltext = \"\"\n",
    "        for page in doc:\n",
    "            text = page.get_text()\n",
    "            text = text.replace(\"\\n\",\" \")\n",
    "            text = text.replace(\"[^a-zA-Z0-9]\", \" \");\n",
    "            text = re.sub('\\W+',' ', text)\n",
    "            text = re.sub('[^A-Za-z0-9]',' ', text)\n",
    "            finaltext += text\n",
    "\n",
    "        if remove_line:\n",
    "            finaltext = text = re.sub('\\s', \" \", text)\n",
    "\n",
    "    return finaltext\n",
    "\n",
    "text = extract_text('./sample/cv/Curriculum Vitae Zaky (ver2 Oct 2021) - Ahmad Zaky Nabhan.pdf')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style='ent')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'database administration',\n 'hc specialist',\n 'human capital information system',\n 'human capital staff',\n 'people development',\n 'recruitment assessment staff',\n 'senior hc staff',\n 'talent monitoring'}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "job = set()\n",
    "\n",
    "for a in doc.ents:\n",
    "    job.add(str(a).lower())\n",
    "\n",
    "job"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}